{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61cda5ee",
   "metadata": {},
   "source": [
    "線形単回帰分析\n",
    "==============\n",
    "\n",
    "## データの確認\n",
    "\n",
    "カリフォルニア住宅価格データを使って予測してみましょう。\n",
    "このデータは、1990年のアメリカ合衆国の国勢調査に基づいて作成されたカリフォルニア州の住宅に関する情報を含んでいます。\n",
    "データ数は約2万で、以下の8つの特徴量があります。\n",
    "\n",
    "| 特徴量 | 説明 | 単位 |\n",
    "|--------|------|------|\n",
    "| MedInc | その地域の世帯収入の中央値 | なし（スケーリング済み） |\n",
    "| HouseAge | その地域の住宅の平均年齢 | 年 |\n",
    "| AveRooms | 平均部屋数 | 部屋数 |\n",
    "| AveBedrms | 平均寝室数 | 部屋数 |\n",
    "| Population | その地域の人口 | 人 |\n",
    "| AveOccup | 平均世帯人数 | 人 |\n",
    "| Latitude | 緯度 | 度 |\n",
    "| Longitude | 経度 | 度 |\n",
    "\n",
    "この8つの特徴量から住宅価格を予測します。\n",
    "予測のために使われるデータを{index}`特徴量<とくちょうりょう - 特徴量>`、\n",
    "予測するデータを{index}`目的変数<もくてきへんすう - 目的変数>`といいます。\n",
    "ここでの目的変数は住宅価格になります。\n",
    "\n",
    "pythonでデータを確認するプログラムを書いてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd9c4da",
   "metadata": {
    "mystnb": {
     "number_source_lines": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/work/ds-seminar/ds-seminar/.venv/lib/python3.11/site-packages/sklearn/datasets/_base.py:1519: UserWarning: Retry downloading from url: https://ndownloader.figshare.com/files/5976036\n",
      "  warnings.warn(f\"Retry downloading from url: {remote.url}\")\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fetch_california_housing\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m dataset = \u001b[43mfetch_california_housing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n\u001b[32m      6\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mPrice\u001b[39m\u001b[33m'\u001b[39m] = dataset.target\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/ds-seminar/ds-seminar/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/ds-seminar/ds-seminar/.venv/lib/python3.11/site-packages/sklearn/datasets/_california_housing.py:177\u001b[39m, in \u001b[36mfetch_california_housing\u001b[39m\u001b[34m(data_home, download_if_missing, return_X_y, as_frame, n_retries, delay)\u001b[39m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mData not found and `download_if_missing` is False\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    173\u001b[39m logger.info(\n\u001b[32m    174\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mDownloading Cal. housing from \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(ARCHIVE.url, data_home)\n\u001b[32m    175\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m archive_path = \u001b[43m_fetch_remote\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43mARCHIVE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_home\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tarfile.open(mode=\u001b[33m\"\u001b[39m\u001b[33mr:gz\u001b[39m\u001b[33m\"\u001b[39m, name=archive_path) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    185\u001b[39m     cal_housing = np.loadtxt(\n\u001b[32m    186\u001b[39m         f.extractfile(\u001b[33m\"\u001b[39m\u001b[33mCaliforniaHousing/cal_housing.data\u001b[39m\u001b[33m\"\u001b[39m), delimiter=\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    187\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/ds-seminar/ds-seminar/.venv/lib/python3.11/site-packages/sklearn/datasets/_base.py:1513\u001b[39m, in \u001b[36m_fetch_remote\u001b[39m\u001b[34m(remote, dirname, n_retries, delay)\u001b[39m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1512\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1513\u001b[39m         \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremote\u001b[49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1514\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1515\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (URLError, \u001b[38;5;167;01mTimeoutError\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.rye/py/cpython@3.11.11/lib/python3.11/urllib/request.py:241\u001b[39m, in \u001b[36murlretrieve\u001b[39m\u001b[34m(url, filename, reporthook, data)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    225\u001b[39m \u001b[33;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[32m    226\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    237\u001b[39m \u001b[33;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[32m    238\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    239\u001b[39m url_type, path = _splittype(url)\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m contextlib.closing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[32m    242\u001b[39m     headers = fp.info()\n\u001b[32m    244\u001b[39m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[32m    245\u001b[39m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.rye/py/cpython@3.11.11/lib/python3.11/urllib/request.py:216\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    215\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.rye/py/cpython@3.11.11/lib/python3.11/urllib/request.py:525\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    524\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.rye/py/cpython@3.11.11/lib/python3.11/urllib/request.py:634\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    632\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.rye/py/cpython@3.11.11/lib/python3.11/urllib/request.py:563\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    561\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    562\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.rye/py/cpython@3.11.11/lib/python3.11/urllib/request.py:496\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    495\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    498\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.rye/py/cpython@3.11.11/lib/python3.11/urllib/request.py:643\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "dataset = fetch_california_housing()\n",
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df['Price'] = dataset.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb47024",
   "metadata": {},
   "source": [
    "このプログラムを実行すると、カリフォルニア住宅価格データセットの最初の5行が表示され、各特徴量と住宅価格（Price）を確認できます。\n",
    "\n",
    "2行目は`scikit-learn`ライブラリからデータセットを取得する関数をインポートしています。\n",
    "`scikit-learn`は、Pythonのための機械学習ライブラリです。\n",
    "データ分析や統計モデリングのために広く使用されており、多様な機械学習アルゴリズムを提供しています。\n",
    "\n",
    "5行目は`pandas`を使って、データセットの特徴量データをデータフレームに変換します。\n",
    "`dataset.data`には特徴量の数値データが、`dataset.feature_names`には特徴量の名前が含まれています。\n",
    "これにより、各列に適切な名前が付けられたデータフレームが作成されます。\n",
    "6行目はデータフレームに新しい列`Price`を追加し、そこにデータセットの目的変数（住宅価格）を格納します。\n",
    "`dataset.target`には住宅価格のデータが含まれています。\n",
    "\n",
    "住宅価格と相関が高い特徴量を選ぶと予測が当てやすくなると思います。\n",
    "住宅価格とそれぞれの特徴量との相関係数を計算し、ヒートマップとして視覚化するコードを書きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf603618",
   "metadata": {
    "mystnb": {
     "number_source_lines": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "heatmap = sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
    "plt.title(\"相関係数のヒートマップ\")\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e4dd0",
   "metadata": {},
   "source": [
    "対角線は自分との相関なのですべて1になります。\n",
    "これは、ある変数が自身と完全に相関しているためです。\n",
    "\n",
    "`df.corr()`は、データフレーム（df）内の数値列間の相関係数を計算します。\n",
    "\n",
    "プログラムの結果から、MedIncが住宅価格と最も相関が高そうなので、\n",
    "特徴量をMedInc、目的変数を住宅価格として考えます。\n",
    "\n",
    "## データクリーニング\n",
    "\n",
    "次に、MedIncと住宅価格がどのような関係になっているかを図で確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d6c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df['MedInc'], y=df['Price'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f1f3ff",
   "metadata": {},
   "source": [
    "この図を見ると、Priceが5のところに一直線に並んでいたり、\n",
    "MedIncが10以上のところでまばらに存在しています。\n",
    "このようなデータは予測に悪影響を及ぼす可能性があります。\n",
    "\n",
    "そのため、これらのデータポイントを適切に処理する必要があります。\n",
    "外れ値を除去したり、変換したりすれば、より信頼性の高い分析が可能になります。\n",
    "\n",
    "{ref}`subsec-normal`のところでも述べたように、平均から3標準偏差以上離れたデータを異常値や外れ値とする方法があり、\n",
    "ここでは、その方法でデータの分布を改善してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2184154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_sigma(df, column, sigma=3):\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    lower_bound = mean - sigma * std\n",
    "    upper_bound = mean + sigma * std\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "df_cleaned = remove_outliers_sigma(df, 'MedInc')\n",
    "df_cleaned = remove_outliers_sigma(df_cleaned, 'Price', 2.6)\n",
    "\n",
    "sns.scatterplot(x=df_cleaned['MedInc'], y=df_cleaned['Price'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88228ca4",
   "metadata": {},
   "source": [
    "前よりは改善されたのではないでしょうか。\n",
    "住宅価格（Price）に関しては3シグマではなく、2.6シグマを採用しました。\n",
    "この値は様々な試行を経て決定しました。\n",
    "厳密な理論的根拠はありませんが、結果としておよそ99%のデータが保持されるようになっています。\n",
    "\n",
    "## 最小二乗法\n",
    "\n",
    "さて、このデータを使って予測をしてみましょう。\n",
    "MedIncから住宅価格を予測するので、以下のような関数$f$を求めればよいでしょう。\n",
    "\n",
    "```{math}\n",
    "\\text{住宅価格} = f(\\text{MedInc})\n",
    "```\n",
    "\n",
    "これだけでは関数の具体的な形は分かりません。\n",
    "この関数$f$の形を決定するために、{index}`回帰モデル<かいきもでる - 回帰モデル>`を使用します。\n",
    "\n",
    "回帰モデルは、特徴量と目的変数の関係を数学的に表現する方法です。\n",
    "最も単純で広く使用されている回帰モデルは{index}`線形回帰モデル<せんけいかいきもでる - 線形回帰モデル>`です。\n",
    "線形回帰モデルでは、関数$f$を直線で近似します。\n",
    "\n",
    "```{math}\n",
    "f(\\text{MedInc}) = a \\cdot \\text{MedInc} + b\n",
    "```\n",
    "\n",
    "では、このモデルの未知のパラメータ$a$と$b$をどのように決定すれば良いでしょうか。ここで最小二乗法を使います。\n",
    "\n",
    "最小二乗法は、実際の観測値と予測値の差（残差）の二乗和を最小化するようなパラメータを見つける方法です。\n",
    "具体的には、以下の式を最小化します。\n",
    "\n",
    "```{math}\n",
    "\\sum_{i=1}^n (y_i - (b + a x_i))^2\n",
    "```\n",
    "\n",
    "ここで、$y_i$は実際の住宅価格、$x_i$はMedIncの値、$n$はデータポイントの総数です。\n",
    "\n",
    "この最小化問題を解けば、データに最もフィットする直線、つまり最適な$a$と$b$を見つけられます。\n",
    "\n",
    "では、この最小化問題を解くプログラムを書きましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f410fe",
   "metadata": {
    "mystnb": {
     "number_source_lines": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = df_cleaned['MedInc'].values.reshape(-1, 1)\n",
    "y = df_cleaned['Price'].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "print(f\"最適なパラメータ: a (傾き) = {model.coef_[0]:.4f}, b (切片) = {model.intercept_:.4f}\")\n",
    "\n",
    "sns.regplot(x='MedInc', y='Price', data=df_cleaned, \n",
    "            scatter_kws={'edgecolor': 'white'},\n",
    "            line_kws={'color': 'red'}\n",
    "            )\n",
    "\n",
    "plt.xlabel('MedInc')\n",
    "plt.ylabel('住宅価格')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985b1669",
   "metadata": {},
   "source": [
    "最小二乗法を使って傾きと切片を求めて直線を引いたものが図中の赤線になります。\n",
    "\n",
    "プログラムの2行目は`scikit-learn`ライブラリの`linear_model`モジュールにある`LinearRegression`クラスをインポートしています。\n",
    "`linear_model`は線形モデルに関連する様々な機能があり、その中でも最小二乗法による線形回帰をするクラスが`LinearRegression`です。\n",
    "\n",
    "4、5行目では、dfのデータを`LinearRegression`が扱えるデータへ変換しています。\n",
    "`df_cleaned['MedInc'].values`は、MedInc列からデータをNumPy配列として取り出します。\n",
    "`.reshape(-1, 1)`は1次元の配列を2次元の配列に変換します。\n",
    "`-1` は「この次元のサイズを自動的に決定する」という意味です。\n",
    "`1` は「各行が1つの要素を持つ」という意味です。\n",
    "結果として、$n$行1列の2次元配列が生成されます。ここで$n$はデータの数です。\n",
    "この変換は、scikit-learnの多くの関数が特徴量として2次元配列、\n",
    "目的変数として1次元配列の形式のデータ入力を必要とするためです。\n",
    "\n",
    "7行目で線形回帰モデルを作り、8行目でそのモデルに対してfitメソッドを呼びます。\n",
    "fitメソッドは、準備したデータ（XとY）を使ってモデルを調整します。\n",
    "この過程を**学習**と呼びます。\n",
    "学習とは、モデルがデータの特徴やパターンを理解し、それに基づいて最適な予測ができるようになることを指します。\n",
    "\n",
    "10行目は学習後のモデルから、最適な直線の傾き（coefficient）と切片（intercept）を取得して表示しています。\n",
    "12行目の`regplot`は、seabornライブラリの関数で、散布図と回帰直線を同時に描画します。\n",
    "\n",
    "## 性能評価\n",
    "\n",
    "先ほどのプログラムではすべてのデータを使って直線を求めていました。\n",
    "しかし、これでは新しいデータを得るまで、そのモデルの精度（性能）を評価できません。\n",
    "また、モデルの性能評価はどのようにすればよいのでしょうか。\n",
    "\n",
    "この問題を解決し、モデルの性能を適切に評価するために、データを2つのグループに分けます。\n",
    "最小二乗法を使用して最適なパラメータを求めるための**訓練データ**と\n",
    "モデルを評価するための**テストデータ**です。\n",
    "訓練に使用していないテストデータで予測を行い、その結果と実際の値を比較することで、モデルの性能を評価します。\n",
    "\n",
    "ここではモデルの性能評価方法として2つ紹介します。\n",
    "- {index}`平均二乗誤差<へいきんにじょうごさ - 平均二乗誤差>`（{index}`MSE: Mean Squared Error<Mean Squared Error - MSE>`）\n",
    "- {index}`決定係数<けっていけいすう - 決定係数>`（{index}`R²: Coefficient of Determination<Coefficient of Determination - R²>`）\n",
    "\n",
    "この方法は回帰問題での性能評価でよく使われます。\n",
    "\n",
    "MSEは、予測値と実際の値の差（誤差）の二乗の平均です。\n",
    "数式で表すと\n",
    "```{math}\n",
    "\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "```\n",
    "となります。\n",
    "この値が0に近いほど良いモデルといえます。\n",
    "\n",
    "決定係数は、モデルがデータの変動をどれだけ説明できるかを示す指標です。\n",
    "\n",
    "数式で表すと\n",
    "```{math}\n",
    "R^2 = 1 - \\frac{\\displaystyle\\sum_{i=1}^n (y_i - \\hat{y}_i)^2}{\\displaystyle\\sum_{i=1}^n (y_i - \\bar{y})^2}\n",
    "```\n",
    "となります。\n",
    "最大で1の値となり、1に近いほど良いモデルといえます。\n",
    "\n",
    "ここで、$y_i$は実際の値、$\\hat{y}_i$は予測値、$\\bar{y}$は$y$の平均値、$n$ はデータ数です。\n",
    "\n",
    "では、データを分割してモデルを評価するプログラムを書きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d9ff05",
   "metadata": {
    "mystnb": {
     "number_source_lines": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred):.2f}\")\n",
    "print(f\"R2: {r2_score(y_test, y_pred):.2f}\")\n",
    "\n",
    "sns.scatterplot(x=X_test.squeeze(), y=y_test, color='blue', label='実際のデータ')\n",
    "sns.lineplot(x=X_test.squeeze(), y=y_pred, color='red', label='予測')\n",
    "plt.xlabel('MedInc')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac49f3e",
   "metadata": {},
   "source": [
    "4行目は`train_test_split`を使ってデータを2つに分割しています。\n",
    "`test_size=0.2`は、全データの20%をテスト用、80%を訓練用に使うという意味です。\n",
    "\n",
    "11行目は`mean_squared_error`を使って平均二乗誤差を計算、12行目は`r2_score`を使って決定係数を計算し、モデルの良さを確認しています。\n",
    "決定係数は$R^2$あまり高くはないため、モデルに改善の余地があるといえます。\n",
    "\n",
    "13行目からのプログラムでテストデータと予測結果をグラフ上に描画しています。\n",
    "青い点は実際のテストデータを表し、赤い線は予測を表しています。\n",
    "この予測線は、訓練データを使って学習した線形回帰モデルによるものです。\n",
    "\n",
    "線形回帰の場合、予測結果は直線になります。\n",
    "これは、線形回帰が入力変数と出力変数の間に線形の関係を仮定しているためです。\n",
    "したがって、予測値はこの直線上に位置します。"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "source_map": [
   13,
   41,
   53,
   70,
   90,
   104,
   107,
   119,
   132,
   174,
   198,
   260,
   283
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}